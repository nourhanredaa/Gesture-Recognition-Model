{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "007ea8ff-4fab-481b-bb91-c7f38ccb2416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hadyh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22857433-939c-46f6-af2c-03d4319c5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(frame):\n",
    "    # Load the MediaPipe Hands model\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    \n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "    lm = np.zeros((2, 21, 3))\n",
    "    for i, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "        for j, landmark in enumerate(hand_landmarks.landmark):\n",
    "            lm[i][j] = [landmark.x, landmark.y, landmark.z]    \n",
    "    hands.close()\n",
    "\n",
    "    return lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50553b00-5261-481f-990c-ca071bc5f3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hadyh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hadyh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hadyh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('Models/gesture_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219ffabf-0638-4833-9985-3267e0e20ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    0: 'closedfist',\n",
    "    1: 'four',\n",
    "    2: 'openpalm',\n",
    "    3: 'pointup',\n",
    "    4: 'three',\n",
    "    5: 'thumbsdown',\n",
    "    6: 'thumbsup',\n",
    "    7: 'victory'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44db2ca0-344c-4be6-854a-cd0db23df33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'NoneType' object is not iterable\n",
      "Error: 'NoneType' object is not iterable\n",
      "Error: 'NoneType' object is not iterable\n",
      "Error: 'NoneType' object is not iterable\n",
      "Error: 'NoneType' object is not iterable\n",
      "Error: 'NoneType' object is not iterable\n",
      "Error: 'NoneType' object is not iterable\n",
      "Error: 'NoneType' object is not iterable\n",
      "Error: 'NoneType' object is not iterable\n",
      "Error: 'NoneType' object is not iterable\n",
      "Error: 'NoneType' object is not iterable\n",
      "Error: 'NoneType' object is not iterable\n",
      "Error: 'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"Models/converted_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    processed_frame = extract(frame).reshape(-1,42,3)\n",
    "    return processed_frame\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "text = 'No Gesture Yet'\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Couldn't open webcam\")\n",
    "    exit()\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Error: Couldn't read frame\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    if frame_count % 30 != 0: \n",
    "        cv2.putText(frame,\n",
    "            text,\n",
    "            org=(50, 50),  \n",
    "            fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            fontScale=1, \n",
    "            color=(0, 0, 255), \n",
    "            thickness=2)\n",
    "\n",
    "        cv2.imshow('Webcam', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        processed_frame = preprocess_frame(frame)\n",
    "        \n",
    "        interpreter.set_tensor(input_details[0]['index'], np.array(processed_frame, dtype=np.float32))\n",
    "\n",
    "        interpreter.invoke()\n",
    "\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "        predicted_class = np.argmax(output_data)\n",
    "\n",
    "        text = mapping[predicted_class]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        continue\n",
    "\n",
    "    cv2.imshow('Webcam', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c48b6ba-0f96-42f1-829c-1174f1ef368d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'victory'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd159390-0eff-4e71-bd55-1f3853094314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mapping[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf3135-0862-4d59-8cf8-cdc7e7a6e592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
